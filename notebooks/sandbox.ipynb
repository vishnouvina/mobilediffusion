{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/29/2024 02:20:50 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: bf16\n",
      "\n",
      "{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'variance_type', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor', 'latents_mean', 'latents_std', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'resnet_out_scale_factor', 'class_embed_type', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'addition_embed_type_num_heads', 'dropout', 'reverse_transformer_layers_per_block', 'resnet_time_scale_shift', 'mid_block_type', 'encoder_hid_dim', 'time_embedding_act_fn', 'addition_time_embed_dim', 'addition_embed_type', 'transformer_layers_per_block', 'time_embedding_type', 'conv_out_kernel', 'resnet_skip_time_act', 'conv_in_kernel', 'attention_type', 'mid_block_only_cross_attention', 'time_embedding_dim', 'class_embeddings_concat', 'time_cond_proj_dim', 'encoder_hid_dim_type', 'num_attention_heads'} was not found in config. Values will be initialized to default values.\n",
      "{'resnet_out_scale_factor', 'class_embed_type', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'addition_embed_type_num_heads', 'dropout', 'reverse_transformer_layers_per_block', 'resnet_time_scale_shift', 'mid_block_type', 'encoder_hid_dim', 'time_embedding_act_fn', 'addition_time_embed_dim', 'addition_embed_type', 'transformer_layers_per_block', 'time_embedding_type', 'conv_out_kernel', 'resnet_skip_time_act', 'conv_in_kernel', 'attention_type', 'mid_block_only_cross_attention', 'time_embedding_dim', 'class_embeddings_concat', 'time_cond_proj_dim', 'encoder_hid_dim_type', 'num_attention_heads'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.12it/s]\n",
      "Loading dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 10143.95it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishnou-vinayagame\u001b[0m (\u001b[33mvishnou\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/w/340/vishnouvina/wandb/run-20240329_022056-2x8jqvkp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhearty-lake-90\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vishnou/text2image-fine-tune\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vishnou/text2image-fine-tune/runs/2x8jqvkp/workspace\u001b[0m\n",
      "03/29/2024 02:20:59 - INFO - __main__ - ***** Running training *****\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Num examples = 20072\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Num Epochs = 32\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Total optimization steps = 10000\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Number params Student = 327050628\n",
      "03/29/2024 02:20:59 - INFO - __main__ -   Number params Teacher = 865910724\n",
      "03/29/2024 02:20:59 - INFO - __main__ - Checkpoint 'latest' does not exist. Starting a new training run.\n",
      "Steps:   0%|      | 7/10000 [00:40<14:38:59,  5.28s/it, lr=1e-5, step_loss=56.3]/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/PIL/Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Steps:   2%|    | 250/10000 [22:07<14:24:46,  5.32s/it, lr=1e-5, step_loss=51.4]03/29/2024 02:43:06 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-250\n",
      "Configuration saved in sd-laion-art/checkpoint-250/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-250/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 02:43:16 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-250/optimizer.bin\n",
      "03/29/2024 02:43:16 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-250/scheduler.bin\n",
      "03/29/2024 02:43:16 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-250/sampler.bin\n",
      "03/29/2024 02:43:16 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-250/random_states_0.pkl\n",
      "03/29/2024 02:43:16 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-250\n",
      "Steps:   3%|â–   | 314/10000 [27:53<12:18:45,  4.58s/it, lr=1e-5, step_loss=49.1]03/29/2024 02:48:52 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 730.12it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "scheduler.bin:   0%|                                | 0.00/1.00k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.10M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 442k/461k [00:00<00:00, 4.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   1%|â–Ž                   | 16.4k/1.10M [00:00<00:08, 134kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:08, 117kB/s]\u001b[A\n",
      "\n",
      "scheduler.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.00k/1.00k [00:00<00:00, 6.37kB/s]\u001b[A\u001b[A\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 69.7kB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.73MB/s]\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.10M/1.10M [00:00<00:00, 3.22MB/s]\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 2.34MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 5 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:   5%|â–   | 500/10000 [44:26<13:49:22,  5.24s/it, lr=1e-5, step_loss=48.4]03/29/2024 03:05:25 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-500\n",
      "Configuration saved in sd-laion-art/checkpoint-500/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 03:05:33 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-500/optimizer.bin\n",
      "03/29/2024 03:05:33 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-500/scheduler.bin\n",
      "03/29/2024 03:05:33 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-500/sampler.bin\n",
      "03/29/2024 03:05:33 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-500/random_states_0.pkl\n",
      "03/29/2024 03:05:33 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-500\n",
      "Steps:   6%|â–Ž   | 628/10000 [55:51<11:46:33,  4.52s/it, lr=1e-5, step_loss=46.6]03/29/2024 03:16:50 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1382.66it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.09M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:06, 147kB/s]\u001b[A\n",
      "\n",
      "adapter_model.safetensors:   4%|â–            | 16.4k/461k [00:00<00:02, 151kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.09M/1.09M [00:00<00:00, 3.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 2.55MB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.17MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 1/4 [00:00<00:01,  1.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:01<00:00, 12.6kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:   8%|â– | 750/10000 [1:06:53<13:43:32,  5.34s/it, lr=1e-5, step_loss=46.1]03/29/2024 03:27:52 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-750\n",
      "Configuration saved in sd-laion-art/checkpoint-750/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-750/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 03:28:01 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-750/optimizer.bin\n",
      "03/29/2024 03:28:01 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-750/scheduler.bin\n",
      "03/29/2024 03:28:01 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-750/sampler.bin\n",
      "03/29/2024 03:28:01 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-750/random_states_0.pkl\n",
      "03/29/2024 03:28:01 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-750\n",
      "Steps:   9%|â–   | 942/10000 [1:23:54<11:51:57,  4.72s/it, lr=1e-5, step_loss=46]03/29/2024 03:44:53 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 924.50it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:06, 157kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 524k/1.05M [00:00<00:00, 5.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 119kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 71.6kB/s]\u001b[A\u001b[A\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.05M/1.05M [00:00<00:00, 3.88MB/s]\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 3.27MB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.24MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:  10%| | 1000/10000 [1:29:15<12:55:15,  5.17s/it, lr=1e-5, step_loss=46.7]03/29/2024 03:50:14 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-1000\n",
      "Configuration saved in sd-laion-art/checkpoint-1000/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-1000/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 03:50:23 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-1000/optimizer.bin\n",
      "03/29/2024 03:50:23 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-1000/scheduler.bin\n",
      "03/29/2024 03:50:23 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-1000/sampler.bin\n",
      "03/29/2024 03:50:23 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-1000/random_states_0.pkl\n",
      "03/29/2024 03:50:23 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-1000\n",
      "Steps:  12%|â–| 1250/10000 [1:51:33<12:47:57,  5.27s/it, lr=1e-5, step_loss=43.5]03/29/2024 04:12:33 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-1250\n",
      "Configuration saved in sd-laion-art/checkpoint-1250/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-1250/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 04:12:42 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-1250/optimizer.bin\n",
      "03/29/2024 04:12:42 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-1250/scheduler.bin\n",
      "03/29/2024 04:12:42 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-1250/sampler.bin\n",
      "03/29/2024 04:12:42 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-1250/random_states_0.pkl\n",
      "03/29/2024 04:12:42 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-1250\n",
      "Steps:  13%|â–| 1256/10000 [1:52:13<12:27:55,  5.13s/it, lr=1e-5, step_loss=47.5]03/29/2024 04:13:12 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1416.68it/s]\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 7 LFS files:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 108kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 124kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   4%|â–            | 16.4k/461k [00:00<00:03, 115kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 67.4kB/s]\u001b[A\u001b[A\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 52.8kB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.41MB/s]\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 2.56MB/s]\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 3.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.06M/1.06M [00:00<00:00, 6.18MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:01<00:00, 789kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 7 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:  15%|â–| 1500/10000 [2:14:15<12:44:44,  5.40s/it, lr=1e-5, step_loss=45.8]03/29/2024 04:35:14 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-1500\n",
      "Configuration saved in sd-laion-art/checkpoint-1500/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-1500/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 04:35:22 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-1500/optimizer.bin\n",
      "03/29/2024 04:35:22 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-1500/scheduler.bin\n",
      "03/29/2024 04:35:22 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-1500/sampler.bin\n",
      "03/29/2024 04:35:22 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-1500/random_states_0.pkl\n",
      "03/29/2024 04:35:22 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-1500\n",
      "Steps:  16%|â–| 1570/10000 [2:20:31<10:47:28,  4.61s/it, lr=1e-5, step_loss=46.1]03/29/2024 04:41:31 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1369.72it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.07M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 143kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "adapter_model.safetensors:   4%|â–            | 16.4k/461k [00:00<00:02, 156kB/s]\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:07, 128kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 78.1kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.07M/1.07M [00:00<00:00, 4.26MB/s]\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 3.33MB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.52MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:  18%|â–| 1750/10000 [2:36:51<12:22:34,  5.40s/it, lr=1e-5, step_loss=43.3]03/29/2024 04:57:50 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-1750\n",
      "Configuration saved in sd-laion-art/checkpoint-1750/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-1750/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 04:57:59 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-1750/optimizer.bin\n",
      "03/29/2024 04:57:59 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-1750/scheduler.bin\n",
      "03/29/2024 04:57:59 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-1750/sampler.bin\n",
      "03/29/2024 04:57:59 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-1750/random_states_0.pkl\n",
      "03/29/2024 04:57:59 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-1750\n",
      "Steps:  19%|â–| 1884/10000 [2:48:46<10:18:10,  4.57s/it, lr=1e-5, step_loss=43.1]03/29/2024 05:09:45 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1343.97it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 112kB/s]\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:08, 122kB/s]\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   4%|â–            | 16.4k/461k [00:00<00:03, 114kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 72.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.58MB/s]\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.06M/1.06M [00:00<00:00, 3.10MB/s]\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 2.32MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:  20%|â–| 2000/10000 [2:59:29<11:44:58,  5.29s/it, lr=1e-5, step_loss=46.4]03/29/2024 05:20:29 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-2000\n",
      "Configuration saved in sd-laion-art/checkpoint-2000/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-2000/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 05:20:37 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-2000/optimizer.bin\n",
      "03/29/2024 05:20:37 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-2000/scheduler.bin\n",
      "03/29/2024 05:20:37 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-2000/sampler.bin\n",
      "03/29/2024 05:20:37 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-2000/random_states_0.pkl\n",
      "03/29/2024 05:20:37 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-2000\n",
      "Steps:  22%|â–| 2198/10000 [3:17:08<10:05:42,  4.66s/it, lr=1e-5, step_loss=44.8]03/29/2024 05:38:07 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1325.84it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.08M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:06, 141kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   2%|â–Ž                   | 16.4k/1.08M [00:00<00:06, 156kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 85.0kB/s]\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 3.09MB/s]\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.08M/1.08M [00:00<00:00, 3.34MB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.31MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 1/4 [00:00<00:01,  1.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:  22%|â–| 2250/10000 [3:22:09<11:29:14,  5.34s/it, lr=1e-5, step_loss=45.4]03/29/2024 05:43:08 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-2250\n",
      "Configuration saved in sd-laion-art/checkpoint-2250/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-2250/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 05:43:17 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-2250/optimizer.bin\n",
      "03/29/2024 05:43:17 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-2250/scheduler.bin\n",
      "03/29/2024 05:43:17 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-2250/sampler.bin\n",
      "03/29/2024 05:43:17 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-2250/random_states_0.pkl\n",
      "03/29/2024 05:43:17 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-2250\n",
      "Steps:  25%|â–Ž| 2500/10000 [3:44:24<11:26:57,  5.50s/it, lr=1e-5, step_loss=44.1]03/29/2024 06:05:23 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-2500\n",
      "Configuration saved in sd-laion-art/checkpoint-2500/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-2500/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 06:05:32 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-2500/optimizer.bin\n",
      "03/29/2024 06:05:32 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-2500/scheduler.bin\n",
      "03/29/2024 06:05:32 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-2500/sampler.bin\n",
      "03/29/2024 06:05:32 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-2500/random_states_0.pkl\n",
      "03/29/2024 06:05:32 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-2500\n",
      "Steps:  25%|â–Œ | 2512/10000 [3:45:35<9:42:09,  4.66s/it, lr=1e-5, step_loss=42.2]03/29/2024 06:06:34 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1321.94it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 7 LFS files:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:06, 153kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "optimizer.bin:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 328k/997k [00:00<00:00, 3.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 120kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 105kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 64.8kB/s]\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 3.69MB/s]\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 54.5kB/s]\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 3.42MB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.16MB/s]\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 7 LFS files:  14%|â–ˆâ–ˆâ–ˆâ–Œ                     | 1/7 [00:00<00:02,  2.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.07M/1.07M [00:00<00:00, 6.15MB/s]\u001b[A\u001b[A\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 2.18MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 7 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:  28%|â–Ž| 2750/10000 [4:07:13<10:46:46,  5.35s/it, lr=1e-5, step_loss=44.6]03/29/2024 06:28:12 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-2750\n",
      "Configuration saved in sd-laion-art/checkpoint-2750/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-2750/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 06:28:21 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-2750/optimizer.bin\n",
      "03/29/2024 06:28:21 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-2750/scheduler.bin\n",
      "03/29/2024 06:28:21 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-2750/sampler.bin\n",
      "03/29/2024 06:28:21 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-2750/random_states_0.pkl\n",
      "03/29/2024 06:28:21 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-2750\n",
      "Steps:  28%|â–Œ | 2826/10000 [4:14:01<9:22:53,  4.71s/it, lr=1e-5, step_loss=42.8]03/29/2024 06:35:00 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1434.52it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.09M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   4%|â–            | 16.4k/461k [00:00<00:02, 154kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:  17%|â–ˆâ–ˆâ–ˆâ–Ž                | 180k/1.09M [00:00<00:00, 1.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:07, 129kB/s]\u001b[A\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 63.3kB/s]\u001b[A\u001b[A\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 3.13MB/s]\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.09M/1.09M [00:00<00:00, 3.34MB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.35MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Steps:  30%|â–Ž| 3000/10000 [4:29:58<10:10:30,  5.23s/it, lr=1e-5, step_loss=42.5]03/29/2024 06:50:57 - INFO - accelerate.accelerator - Saving current state to sd-laion-art/checkpoint-3000\n",
      "Configuration saved in sd-laion-art/checkpoint-3000/unet/config.json\n",
      "Model weights saved in sd-laion-art/checkpoint-3000/unet/diffusion_pytorch_model.safetensors\n",
      "03/29/2024 06:51:07 - INFO - accelerate.checkpointing - Optimizer state saved in sd-laion-art/checkpoint-3000/optimizer.bin\n",
      "03/29/2024 06:51:07 - INFO - accelerate.checkpointing - Scheduler state saved in sd-laion-art/checkpoint-3000/scheduler.bin\n",
      "03/29/2024 06:51:07 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in sd-laion-art/checkpoint-3000/sampler.bin\n",
      "03/29/2024 06:51:07 - INFO - accelerate.checkpointing - Random states saved in sd-laion-art/checkpoint-3000/random_states_0.pkl\n",
      "03/29/2024 06:51:07 - INFO - __main__ - Saved state to sd-laion-art/checkpoint-3000\n",
      "Steps:  31%|â–‹ | 3140/10000 [4:42:29<8:53:52,  4.67s/it, lr=1e-5, step_loss=46.5]03/29/2024 07:03:28 - INFO - __main__ - Running validation... \n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]\u001b[A{'dynamic_thresholding_ratio', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'sample_max_value', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 1430.93it/s]\n",
      "\n",
      "optimizer.bin:   0%|                                 | 0.00/997k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "random_states_0.pkl:   0%|                          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Upload 4 LFS files:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "val_imgs_grid.png:   0%|                            | 0.00/1.08M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   0%|                     | 0.00/461k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.safetensors:   4%|â–            | 16.4k/461k [00:00<00:02, 163kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 126kB/s]\u001b[A\u001b[A\n",
      "optimizer.bin:   2%|â–                        | 16.4k/997k [00:00<00:07, 129kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "random_states_0.pkl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.3k/14.3k [00:00<00:00, 80.1kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "val_imgs_grid.png: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.08M/1.08M [00:00<00:00, 3.60MB/s]\n",
      "adapter_model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461k/461k [00:00<00:00, 1.47MB/s]\n",
      "optimizer.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997k/997k [00:00<00:00, 2.10MB/s]\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "Steps:  32%|â–‰  | 3223/10000 [4:50:46<10:19:24,  5.48s/it, lr=1e-5, step_loss=44]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/w/340/vishnouvina/mobilediffusion/lora_distill_training.py\", line 1461, in <module>\n",
      "    main()\n",
      "  File \"/w/340/vishnouvina/mobilediffusion/lora_distill_training.py\", line 1190, in main\n",
      "    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/accelerate/utils/operations.py\", line 822, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/accelerate/utils/operations.py\", line 810, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/peft/peft_model.py\", line 563, in forward\n",
      "    return self.get_base_model()(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/unets/unet_2d_condition.py\", line 1216, in forward\n",
      "    sample, res_samples = downsample_block(\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1561, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/unets/unet_2d_blocks.py\", line 1269, in forward\n",
      "    hidden_states = attn(\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py\", line 385, in forward\n",
      "    hidden_states = torch.utils.checkpoint.checkpoint(\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/_compile.py\", line 24, in inner\n",
      "    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py\", line 489, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/_dynamo/external_utils.py\", line 17, in inner\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 489, in checkpoint\n",
      "    ret = function(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py\", line 380, in custom_forward\n",
      "    return module(*inputs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/attention.py\", line 392, in forward\n",
      "    ff_output = self.ff(norm_hidden_states)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/attention.py\", line 664, in forward\n",
      "    hidden_states = module(hidden_states)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/activations.py\", line 103, in forward\n",
      "    return hidden_states * self.gelu(gate)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: - 0.017 MB of 0.017 MB uploaded\r"
     ]
    }
   ],
   "source": [
    "!accelerate launch --mixed_precision=\"bf16\" /w/340/vishnouvina/mobilediffusion/lora_distill_training.py \\\n",
    "    --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1\" \\\n",
    "    --dataset_name=\"fantasyfish/laion-art\" \\\n",
    "    --caption_column=\"text\"\\\n",
    "    --resolution=512 --center_crop --random_flip \\\n",
    "    --num_train_epochs=5 \\\n",
    "    --gradient_accumulation_steps=4 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --max_train_steps=10000 \\\n",
    "    --validation_epochs=1 \\\n",
    "    --distill_level=\"sd_tiny\"\\\n",
    "    --prepare_unet=\"True\"\\\n",
    "    --use_peft\\\n",
    "    --use_8bit_adam\\\n",
    "    --max_grad_norm=1\\\n",
    "    --output_weight=0.5\\\n",
    "    --feature_weight=0.5\\\n",
    "    --learning_rate=1e-05\\\n",
    "    --report_to=\"wandb\"\\\n",
    "    --lora_r=4 \\\n",
    "    --lora_alpha=32 \\\n",
    "    --push_to_hub \\\n",
    "    --hub_model_id=\"sd-laion-art\"\\\n",
    "    --output_dir=\"sd-laion-art\"\\\n",
    "    --resume_from_checkpoint=\"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"Vishnou/sd-laion-art\", torch_dtype=torch.float16)\n",
    "prompt = \"A man in a suit\"\n",
    "image = pipeline(prompt).images[0]\n",
    "image.save(\"my_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"Vishnou/sd-laion-art\", torch_dtype=torch.float16)\n",
    "pipeline.to(\"cuda\")\n",
    "prompt = \"A monkey dancing on a tree\"\n",
    "image = pipeline(prompt).images[0]\n",
    "image.save(\"val_imgs_grid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.components['unet'].num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n",
    "pipeline2.to(\"cuda\")\n",
    "\n",
    "pipeline2.components['unet'].num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mdenv)",
   "language": "python",
   "name": "mdenv"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
