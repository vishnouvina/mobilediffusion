{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --mixed_precision=\"fp16\"  distill_training.py \\\n",
    "  --pretrained_model_name_or_path=\"SG161222/Realistic_Vision_V4.0\" \\\n",
    "  --dataset_name=\"fantasyfish/laion-art\" \\\n",
    "  --resolution=512 --center_crop --random_flip \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --distill_level=\"sd_small\"\\\n",
    "  --prepare_unet=\"True\"\\\n",
    "  --output_weight=0.5\\\n",
    "  --feature_weight=0.5\\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=\"sd-laion-art\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 19:28:03 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "{'timestep_spacing', 'rescale_betas_zero_snr', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'num_attention_heads', 'dropout', 'reverse_transformer_layers_per_block', 'addition_time_embed_dim', 'attention_type', 'transformer_layers_per_block', 'encoder_hid_dim_type'} was not found in config. Values will be initialized to default values.\n",
      "{'num_attention_heads', 'dropout', 'reverse_transformer_layers_per_block', 'addition_time_embed_dim', 'attention_type', 'transformer_layers_per_block', 'encoder_hid_dim_type'} was not found in config. Values will be initialized to default values.\n",
      "/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/attention_processor.py:1851: FutureWarning: Using LoRAAttnProcessor is deprecated. Please use the PEFT backend for all things LoRA. You can install PEFT by running `pip install peft`.\n",
      "  deprecate(\"LoRAAttnProcessor\", \"0.30.0\", deprecation_message, standard_warn=False)\n",
      "/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/lora.py:208: FutureWarning: `LoRALinearLayer` is deprecated and will be removed in version 1.0.0. Use of `LoRALinearLayer` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "  deprecate(\"LoRALinearLayer\", \"1.0.0\", deprecation_message)\n",
      "Resolving data files: 100%|█████████████████████| 24/24 [00:01<00:00, 22.85it/s]\n",
      "Loading dataset shards: 100%|█████████████████| 23/23 [00:00<00:00, 8448.85it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishnou-vinayagame\u001b[0m (\u001b[33mvishnou\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/w/340/vishnouvina/mobilediffusion/wandb/run-20240326_192812-r7cmc11d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mkind-dew-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vishnou/text2image-fine-tune\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vishnou/text2image-fine-tune/runs/r7cmc11d/workspace\u001b[0m\n",
      "03/26/2024 19:28:17 - INFO - __main__ - ***** Running training *****\n",
      "03/26/2024 19:28:17 - INFO - __main__ -   Num examples = 20072\n",
      "03/26/2024 19:28:17 - INFO - __main__ -   Num Epochs = 1\n",
      "03/26/2024 19:28:17 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "03/26/2024 19:28:17 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/26/2024 19:28:17 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "03/26/2024 19:28:17 - INFO - __main__ -   Total optimization steps = 5000\n",
      "Steps:   0%|                                           | 0/5000 [00:00<?, ?it/s]cuda:0 cuda:0 cuda:0\n",
      "Traceback (most recent call last):\n",
      "  File \"/w/340/vishnouvina/mobilediffusion/lora_distill_training.py\", line 1406, in <module>\n",
      "    main()\n",
      "  File \"/w/340/vishnouvina/mobilediffusion/lora_distill_training.py\", line 1183, in main\n",
      "    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/unets/unet_2d_condition.py\", line 1142, in forward\n",
      "    emb = self.time_embedding(t_emb, timestep_cond)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/diffusers/models/embeddings.py\", line 227, in forward\n",
      "    sample = self.linear_1(sample)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mkind-dew-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vishnou/text2image-fine-tune/runs/r7cmc11d/workspace\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240326_192812-r7cmc11d/logs\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 1057, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/w/340/vishnouvina/miniconda3/envs/mdenv/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 673, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/w/340/vishnouvina/miniconda3/envs/mdenv/bin/python', 'lora_distill_training.py', '--pretrained_model_name_or_path=SG161222/Realistic_Vision_V4.0', '--dataset_name=fantasyfish/laion-art', '--caption_column=text', '--resolution=512', '--center_crop', '--random_flip', '--train_batch_size=1', '--num_train_epochs=20', '--gradient_accumulation_steps=4', '--gradient_checkpointing', '--max_train_steps=5000', '--distill_level=sd_tiny', '--prepare_unet=True', '--output_weight=0.5', '--feature_weight=0.5', '--learning_rate=1e-05', '--max_grad_norm=1', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--validation_prompt=A man in a suit', '--report_to=wandb', '--lora_r=4', '--lora_alpha=32', '--push_to_hub', '--hub_model_id=laion-art', '--output_dir=sd-laion-art']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --mixed_precision=\"fp16\"  lora_distill_training.py \\\n",
    "    --pretrained_model_name_or_path=\"SG161222/Realistic_Vision_V4.0\" \\\n",
    "    --dataset_name=\"fantasyfish/laion-art\" \\\n",
    "    --caption_column=\"text\"\\\n",
    "    --resolution=512 --center_crop --random_flip \\\n",
    "    --train_batch_size=1 \\\n",
    "    --num_train_epochs=20 \\\n",
    "    --gradient_accumulation_steps=4 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --max_train_steps=5000 \\\n",
    "    --distill_level=\"sd_tiny\"\\\n",
    "    --prepare_unet=\"True\"\\\n",
    "    --output_weight=0.5\\\n",
    "    --feature_weight=0.5\\\n",
    "    --learning_rate=1e-05 \\\n",
    "    --max_grad_norm=1 \\\n",
    "    --lr_scheduler=\"constant\"\\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --validation_prompt=\"A man in a suit\" \\\n",
    "    --report_to=\"wandb\" \\\n",
    "    --lora_r=4 \\\n",
    "    --lora_alpha=32 \\\n",
    "    --push_to_hub \\\n",
    "    --hub_model_id=\"laion-art\"\\\n",
    "    --output_dir=\"sd-laion-art\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mdenv)",
   "language": "python",
   "name": "mdenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
